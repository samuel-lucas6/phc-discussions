<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style type="text/css">
body { font-size: 16px; }
.cal_brief { text-align: center; }
.cal_brief td:first-child { background: inherit; }
.cal_brief td { background: #ccc; width: 5ex; padding: 2px; }
.cal_big { text-align: center; padding: 0; margin: 0; }
.cal_big td { padding: 0 2px; }
.cal_mon { text-align: center; }
.cal_mon th { font-size: small; padding: 0; margin: 0; }
.cal_mon td { background: #ccc; width: 5ex; height: 1.5em;
	padding: 2px; text-align: right; }
.cal_mon td[colspan] { background: inherit; }
.cal_mon sup { color: #F0F0F0; text-align: left; float: left;
	margin-top: -2pt; font-weight: bold; }
.cal_mon a { text-align: right; margin-left: -4em; float: right; }
</style>

<title>phc-discussions - Re: [PHC] Tradeoff cryptanalysis of Catena, Lyra2, and generic memory-hard
 functions</title>


</head>

<BODY bgcolor="#E0E0E0" text="black" link="blue" alink="red" vlink="navy">



<TABLE bgcolor="white" width="100%" border="0" cellspacing="0" cellpadding="0">
<TR>
<TD width="39%">
<A HREF="http://lists.openwall.net">lists.openwall.net</A>
<TD width="1%" rowspan="3">&nbsp;
<TD width="60%" align="right" rowspan="3">
<A HREF="/">lists</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/announce/">announce</A>&nbsp;
<A HREF="http://www.openwall.com/lists/owl-users/">owl-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/owl-dev/">owl-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/john-users/">john-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/john-dev/">john-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/passwdqc-users/">passwdqc-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/yescrypt/">yescrypt</A>&nbsp;
<A HREF="http://www.openwall.com/lists/popa3d-users/">popa3d-users</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/oss-security/">oss-security</A>&nbsp;
<A HREF="http://www.openwall.com/lists/kernel-hardening/">kernel-hardening</A>&nbsp;
<A HREF="http://www.openwall.com/lists/musl/">musl</A>&nbsp;
<A HREF="http://www.openwall.com/lists/sabotage/">sabotage</A>&nbsp;
<A HREF="http://www.openwall.com/lists/tlsify/">tlsify</A>&nbsp;
<A HREF="http://www.openwall.com/lists/passwords/">passwords</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/crypt-dev/">crypt-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/xvendor/">xvendor</A>&nbsp;
/&nbsp;
<A HREF="/bugtraq/">Bugtraq</A>&nbsp;
<A HREF="/full-disclosure/">Full-Disclosure</A>&nbsp;
<A HREF="/linux-kernel/">linux-kernel</A>&nbsp;
linux-<A HREF="/netdev/">netdev</A>&nbsp;
<A HREF="/linux-ext4/">linux-ext4</A>&nbsp;
<a href="/linux-hardening/">linux-hardening</a>&nbsp;
<a href="/linux-cve-announce/">linux-cve-announce</a>&nbsp;
<a href="/phc-discussions/">PHC</a>&nbsp;
<TR><TD>
<DIV><FONT SIZE="-2"><I>Open Source and information security mailing list archives</I></FONT></DIV>
<TR><TD>&nbsp;
</TABLE>

<TABLE bgcolor="#B4D0DC" width="100%" border="0" cellspacing="0" cellpadding="1">
<TR><TD>
<TABLE width="100%" border="0" cellspacing="0" cellpadding="2">
<TR><TD bgcolor="#ECF8FF">

<a href="https://hashsuite.openwall.net/android">
Hash Suite for Android: free password hash cracker in your pocket</a>


</TABLE>
</TABLE>


<a href="7">[&lt;prev]</a> <a href="9">[next&gt;]</a> <a href="7">[&lt;thread-prev]</a> <a href="9">[thread-next&gt;]</a> <a href=".">[day]</a> <a href="..">[month]</a> <a href="../..">[year]</a> <a href="../../..">[list]</a>
<pre style="white-space: pre-wrap">
Message-ID: &lt;54DE7016.3090701&#64;larc.usp.br&gt;
Date: Fri, 13 Feb 2015 19:43:50 -0200
From: Marcos Simplicio &lt;mjunior&#64;...c.usp.br&gt;
To: discussions&#64;...sword-hashing.net
Subject: Re: [PHC] Tradeoff cryptanalysis of Catena, Lyra2, and generic memory-hard
 functions

Hi, again.

Some considerations inline.

BR,

Marcos.

On 13-Feb-15 17:36, Bill Cox wrote:
&gt; Interesting analysis.  I actually wrote code yesterday almost the same as
&gt; your generic attack.  It's a good algorithm.  I have some comments:
&gt; 
&gt; - Yescrypt is the fastest remaining entry in the PHC, not Lyra2.  Lyra2 is
&gt; the second fastest.  They are the only 2 entries that are faster than
&gt; Scrypt.

Well, maybe we did something wrong in our benchmarks then, because our
implementations are comparisons done in v2 are faster than Yescrypt with
minimal parameters for both functions, both with 1 thread and with
multiple threads...

However, these benchmarks refer to yescrypt v0. Are your comments
referring to v1?

&gt; 
&gt; What data do you have showing Lyra2 is faster?  In particular, for a given
&gt; amount of memory hashed, Lyra2 is always slower than Yescrypt, even on one
&gt; thread, and when Yescrypt's multi-threading option is used as intended,
&gt; Yescrypt can be several times faster.  Also, while Lyra2 uses one Blake2
&gt; reduced round (a good choice, IMO), Yescrypt uses 6 of it's new round
&gt; function.  When using Yescrypt in production, I can easily change 1 line
&gt; and improve it's performance greatly for single-threaded applications.
&gt; Lyra2 is already using only one round, and I will not have that flexibility.

I agree that going below 1 round in Lyra2 is not a great option, but I'm
not sure about the mixing ability of yescrypt's dedicated function when
compared with Blake2. I mean, for a internal of 1024 bits, 1 round of
Blake2 ensures that every bit of the internal and external states depend
on every input bit. Does yescrypt's function do the same? (note: this is
really a question, not a "provocation" of any sort). Because if it does
not, then in theory Blake2 could be reduced even more to match
yescrypt's diffusion capabilities (although personally I would not
recommend it).

&gt; 
&gt; - You're notion of "memory*time" cost in this paper is wrong, leading to
&gt; bizaar and wrong conclusions about Lyra2

I did not check the article in detail, but in Lyra2's v2 document we did
try to take into account Dmitry's attack (as originally described):

1) We got a ~16 times slow down with minimum time_cost = 1 (the minimum
parameter) for a 1/2 TMTO, even when exploring parallelism (end of
section 5.1.4); and

2) We could not see a way to make it much scalable with a high value of
time_cost, especially because its TMTO resistance grows very fast with
this parameter (section 5.1.4.1)

Probably we will have to cross-check the results with this new analysis
(or, better, implement it!), though.

&gt; 
&gt; You claim Lyra2 has a time*memory cost of 0.28 when using a 1/4 memory
&gt; TMTO.  Here's what GPU attackers think that means:  they use 1/4 the
&gt; memory, and they will only have to do 12% more computations.  Yet you say
&gt; the wandering phase for a 1/4 TMTO requires 1876X more computation.  There
&gt; is simply no way you found a 0.28X memory*time attack against Lyra2 by any
&gt; normal use of the memory*time metric.
&gt; 
&gt; What you found is that recomputations can be done in parallel.  While this
&gt; parallelism can help an attacker, time is not equal to the computation tree
&gt; depth.  This depth is simply the theoretical minimum latency for
&gt; recomputing a value, assuming infinite computation resources and power.
&gt; 
&gt; Your generic attack is a good algorithm.  I think I can improve it, but I
&gt; have not yet tried this.  At some point, we may discover that there are
&gt; several rows referring to a previous row R which we keep having to
&gt; recompute.  Instead of making all those new rows have high recomputation
&gt; cost, leading to several of them being kept in memory, we can decide
&gt; instead to store R.  The point where we should do that should not be too
&gt; hard to track.
&gt; 
&gt; In your generic attack, for TMTO &gt; 1/2, for each new value computed, a
&gt; significant percentage of all prior values must be recomputed, leading to a
&gt; computation effort proportional to N^2, where N is the number of original
&gt; computations without a TMTO.  I like that your Table 6 does not claim
&gt; improved memory*time based on tree depth, and instead simply reports both
&gt; recomputations and depth.  However, Table 6 is heavily dependent on N,
&gt; which is not stated.  For very large N, even the 1/3 TMTO attack will have
&gt; very high recomputations.  Maybe state N?
&gt; 
&gt; Bill
&gt; 
</pre>
<p><a href="https://www.openwall.com/blists/">Powered by blists</a> - <a href="https://lists.openwall.net">more mailing lists</a>


<p>




</body>
</html>

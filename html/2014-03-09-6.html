<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style type="text/css">
body { font-size: 16px; }
.cal_brief { text-align: center; }
.cal_brief td:first-child { background: inherit; }
.cal_brief td { background: #ccc; width: 5ex; padding: 2px; }
.cal_big { text-align: center; padding: 0; margin: 0; }
.cal_big td { padding: 0 2px; }
.cal_mon { text-align: center; }
.cal_mon th { font-size: small; padding: 0; margin: 0; }
.cal_mon td { background: #ccc; width: 5ex; height: 1.5em;
	padding: 2px; text-align: right; }
.cal_mon td[colspan] { background: inherit; }
.cal_mon sup { color: #F0F0F0; text-align: left; float: left;
	margin-top: -2pt; font-weight: bold; }
.cal_mon a { text-align: right; margin-left: -4em; float: right; }
</style>

<title>phc-discussions - ROM-on-SSD (Re: [PHC] escrypt 0.3.1)</title>


</head>

<BODY bgcolor="#E0E0E0" text="black" link="blue" alink="red" vlink="navy">



<TABLE bgcolor="white" width="100%" border="0" cellspacing="0" cellpadding="0">
<TR>
<TD width="39%">
<A HREF="http://lists.openwall.net">lists.openwall.net</A>
<TD width="1%" rowspan="3">&nbsp;
<TD width="60%" align="right" rowspan="3">
<A HREF="/">lists</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/announce/">announce</A>&nbsp;
<A HREF="http://www.openwall.com/lists/owl-users/">owl-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/owl-dev/">owl-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/john-users/">john-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/john-dev/">john-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/passwdqc-users/">passwdqc-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/yescrypt/">yescrypt</A>&nbsp;
<A HREF="http://www.openwall.com/lists/popa3d-users/">popa3d-users</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/oss-security/">oss-security</A>&nbsp;
<A HREF="http://www.openwall.com/lists/kernel-hardening/">kernel-hardening</A>&nbsp;
<A HREF="http://www.openwall.com/lists/musl/">musl</A>&nbsp;
<A HREF="http://www.openwall.com/lists/sabotage/">sabotage</A>&nbsp;
<A HREF="http://www.openwall.com/lists/tlsify/">tlsify</A>&nbsp;
<A HREF="http://www.openwall.com/lists/passwords/">passwords</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/crypt-dev/">crypt-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/xvendor/">xvendor</A>&nbsp;
/&nbsp;
<A HREF="/bugtraq/">Bugtraq</A>&nbsp;
<A HREF="/full-disclosure/">Full-Disclosure</A>&nbsp;
<A HREF="/linux-kernel/">linux-kernel</A>&nbsp;
linux-<A HREF="/netdev/">netdev</A>&nbsp;
<A HREF="/linux-ext4/">linux-ext4</A>&nbsp;
<a href="/linux-hardening/">linux-hardening</a>&nbsp;
<a href="/linux-cve-announce/">linux-cve-announce</a>&nbsp;
<a href="/phc-discussions/">PHC</a>&nbsp;
<TR><TD>
<DIV><FONT SIZE="-2"><I>Open Source and information security mailing list archives</I></FONT></DIV>
<TR><TD>&nbsp;
</TABLE>

<TABLE bgcolor="#B4D0DC" width="100%" border="0" cellspacing="0" cellpadding="1">
<TR><TD>
<TABLE width="100%" border="0" cellspacing="0" cellpadding="2">
<TR><TD bgcolor="#ECF8FF">

<a href="https://hashsuite.openwall.net/android">
Hash Suite for Android: free password hash cracker in your pocket</a>


</TABLE>
</TABLE>


<a href="5">[&lt;prev]</a> <a href="7">[next&gt;]</a> <a href="../../../2014/03/08/15">[&lt;thread-prev]</a> <a href=".">[day]</a> <a href="..">[month]</a> <a href="../..">[year]</a> <a href="../../..">[list]</a>
<pre style="white-space: pre-wrap">
Message-ID: &lt;20140309055256.GA2644&#64;openwall.com&gt;
Date: Sun, 9 Mar 2014 09:52:56 +0400
From: Solar Designer &lt;solar&#64;...nwall.com&gt;
To: discussions&#64;...sword-hashing.net
Subject: ROM-on-SSD (Re: [PHC] escrypt 0.3.1)

On Wed, Mar 05, 2014 at 04:44:04AM +0400, Solar Designer wrote:
&gt; - ROM-on-SSD support.  See PERFORMANCE-SSD for a usage example and some
&gt; performance figures.
[...]
&gt; For ROM-on-SSD, support for read-ahead may need to be added, although

Read-ahead was a wrong term to use here.  I meant computing the index in
advance, to allow for prefetch.

&gt; we've achieved reasonable results even without it (with many hardware
&gt; threads sharing one SSD).

One thing I didn't test before posting the above was running more
threads than are supported in hardware.  With ROM-on-SSD, we incur
context switches anyway, so there's no reason to expect exactly matching
the hardware thread count to be optimal.

I tested this now, and there's good speedup with higher thread counts.
Specifically, this result from PERFORMANCE-SSD:

$ ./userom 64 16 rom64.dat
r=512 N=2^8 NROM=2^20
Will use 67108864.00 KiB ROM
         16384.00 KiB RAM
ROM access frequency mask: 0xe
'$7X3$6.6.../....WZaPV7LSUEKMo34.$0E1thDNQBLQG/1hFJWeezbEpOoGYQ7J1mNDgTbG0uJ3'
Benchmarking 1 thread ...
43 c/s real, 65 c/s virtual (63 hashes in 1.45 seconds)
Benchmarking 8 threads ...
180 c/s real, 37 c/s virtual (189 hashes in 1.05 seconds)

improves to:

$ OMP_NUM_THREADS=24 ./userom 64 16 ../rom64.dat
r=512 N=2^8 NROM=2^20
Will use 67108864.00 KiB ROM
         16384.00 KiB RAM
ROM access frequency mask: 0xe
'$7X3$6.6.../....WZaPV7LSUEKMo34.$0E1thDNQBLQG/1hFJWeezbEpOoGYQ7J1mNDgTbG0uJ3'
Benchmarking 1 thread ...
42 c/s real, 64 c/s virtual (63 hashes in 1.49 seconds)
Benchmarking 24 threads ...
215 c/s real, 29 c/s virtual (441 hashes in 2.05 seconds)

(same code revision, same ROM).

This is 19% higher performance with 24 threads than with 8 threads (on a
CPU supporting only 8 hardware threads).  In terms of bandwidth, this
corresponds to 14.0 GB/s from RAM and 225 MB/s from SSD.  Relative to an
SSD-less, RAM-only run (also 16 MiB RAM/hash) on the same machine, this
is 89% of the c/s rate and 86% of RAM bandwidth usage.

I think these results are good enough as-is that advance availability of
the lookup index (and implementation of prefetch) is not worth adding.
The intended use case for ROM-on-SSD is authentication servers, where
the cost settings are limited by what happens at high concurrency -
which is precisely what's optimal for this approach to ROM-on-SSD.
Using e.g. 3 times more RAM for optimal performance is not a problem,
and may actually be an advantage (an attacker with lots of SSDs in a
machine would also need to provide as much RAM per SSD to achieve
similar efficiency).  So we have a good match here.

The SSD read speed may be improved by about a factor of 2 (so to 450 MB/s
for this SSD) by using a much larger block size (than the 64 KiB used in
the tests above), but then there would be less of a dependency on this
being an SSD rather than a HDD (or an array of HDDs).  I ran such tests
as well, and did reach ~450 MB/s from SSD in escrypt, but I dislike
relaxing that dependency on a local SSD (vs. HDD or storage in a distant
network location).  Also, with larger block size the number of random
lookups per hash computed becomes too low.  Anyway, this sort of tuning
is possible, and a decision may be made for each deployment separately.

&gt; Support for simultaneous use of multiple ROMs (with different access
&gt; frequencies) may need to be added, so that when using ROM-on-SSD it is
&gt; possible to also use a ROM-in-RAM.  (Alternatively, the APIs may be
&gt; simplified assuming that such support would never be added.)

Any comments on this?

&gt; Alternatively, ROM-on-SSD may be considered too exotic, and
&gt; simplifications may be made by excluding support for adjusting ROM
&gt; access frequency.

And this?

Alexander
</pre>
<p><a href="https://www.openwall.com/blists/">Powered by blists</a> - <a href="https://lists.openwall.net">more mailing lists</a>


<p>




</body>
</html>

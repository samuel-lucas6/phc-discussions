<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style type="text/css">
body { font-size: 16px; }
.cal_brief { text-align: center; }
.cal_brief td:first-child { background: inherit; }
.cal_brief td { background: #ccc; width: 5ex; padding: 2px; }
.cal_big { text-align: center; padding: 0; margin: 0; }
.cal_big td { padding: 0 2px; }
.cal_mon { text-align: center; }
.cal_mon th { font-size: small; padding: 0; margin: 0; }
.cal_mon td { background: #ccc; width: 5ex; height: 1.5em;
	padding: 2px; text-align: right; }
.cal_mon td[colspan] { background: inherit; }
.cal_mon sup { color: #F0F0F0; text-align: left; float: left;
	margin-top: -2pt; font-weight: bold; }
.cal_mon a { text-align: right; margin-left: -4em; float: right; }
</style>

<title>phc-discussions - Re: [PHC] Multiply with CUDA</title>


</head>

<BODY bgcolor="#E0E0E0" text="black" link="blue" alink="red" vlink="navy">



<TABLE bgcolor="white" width="100%" border="0" cellspacing="0" cellpadding="0">
<TR>
<TD width="39%">
<A HREF="http://lists.openwall.net">lists.openwall.net</A>
<TD width="1%" rowspan="3">&nbsp;
<TD width="60%" align="right" rowspan="3">
<A HREF="/">lists</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/announce/">announce</A>&nbsp;
<A HREF="http://www.openwall.com/lists/owl-users/">owl-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/owl-dev/">owl-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/john-users/">john-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/john-dev/">john-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/passwdqc-users/">passwdqc-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/yescrypt/">yescrypt</A>&nbsp;
<A HREF="http://www.openwall.com/lists/popa3d-users/">popa3d-users</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/oss-security/">oss-security</A>&nbsp;
<A HREF="http://www.openwall.com/lists/kernel-hardening/">kernel-hardening</A>&nbsp;
<A HREF="http://www.openwall.com/lists/musl/">musl</A>&nbsp;
<A HREF="http://www.openwall.com/lists/sabotage/">sabotage</A>&nbsp;
<A HREF="http://www.openwall.com/lists/tlsify/">tlsify</A>&nbsp;
<A HREF="http://www.openwall.com/lists/passwords/">passwords</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/crypt-dev/">crypt-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/xvendor/">xvendor</A>&nbsp;
/&nbsp;
<A HREF="/bugtraq/">Bugtraq</A>&nbsp;
<A HREF="/full-disclosure/">Full-Disclosure</A>&nbsp;
<A HREF="/linux-kernel/">linux-kernel</A>&nbsp;
linux-<A HREF="/netdev/">netdev</A>&nbsp;
<A HREF="/linux-ext4/">linux-ext4</A>&nbsp;
<a href="/linux-hardening/">linux-hardening</a>&nbsp;
<a href="/linux-cve-announce/">linux-cve-announce</a>&nbsp;
<a href="/phc-discussions/">PHC</a>&nbsp;
<TR><TD>
<DIV><FONT SIZE="-2"><I>Open Source and information security mailing list archives</I></FONT></DIV>
<TR><TD>&nbsp;
</TABLE>

<TABLE bgcolor="#B4D0DC" width="100%" border="0" cellspacing="0" cellpadding="1">
<TR><TD>
<TABLE width="100%" border="0" cellspacing="0" cellpadding="2">
<TR><TD bgcolor="#ECF8FF">

<a href="https://hashsuite.openwall.net/android">
Hash Suite for Android: free password hash cracker in your pocket</a>


</TABLE>
</TABLE>


<a href="5">[&lt;prev]</a> <a href="7">[next&gt;]</a> <a href="5">[&lt;thread-prev]</a> <a href="../../../2014/09/22/1">[thread-next&gt;]</a> <a href=".">[day]</a> <a href="..">[month]</a> <a href="../..">[year]</a> <a href="../../..">[list]</a>
<pre style="white-space: pre-wrap">
Message-ID: &lt;20140921204556.GA10662&#64;openwall.com&gt;
Date: Mon, 22 Sep 2014 00:45:56 +0400
From: Solar Designer &lt;solar&#64;...nwall.com&gt;
To: discussions&#64;...sword-hashing.net
Subject: Re: [PHC] Multiply with CUDA

Steve,

I usually don't top-post, but in this case I only want to say that it
appears we understand the technical details mostly in the same way, but
somehow got confused in wording. :-)

I also did not realize you brought this up in context of Makwa or alike.
This explains a lot.

Thanks,

Alexander

On Sun, Sep 21, 2014 at 02:11:21PM -0500, Steve Thomas wrote:
&gt; &gt; On September 20, 2014 at 6:14 AM Solar Designer &lt;solar&#64;...nwall.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Fri, Sep 19, 2014 at 07:00:24PM -0500, Steve Thomas wrote:
&gt; &gt; &gt; but still a little faster than CPUs.
&gt; &gt;
&gt; &gt; I guess you mean in terms of throughput? Per multiprocessor vs. per core?
&gt; &gt;
&gt; 
&gt; Total speed, if you tell a CPU and a GPU to do a bunch of multiplies, then I'm
&gt; pretty sure GPUs are slightly faster. I think the source I got this from was
&gt; doing arbitrarily large integer multiplies. If you only need to do 32 bit
&gt; floating point multiply then GPUs will be "10x" faster.
&gt; 
&gt; 
&gt; &gt; &gt; When comparing
&gt; &gt; &gt; CPUs and GPUs with hash function speeds GPUs are ~10x faster than optimized
&gt; &gt; &gt; SIMD
&gt; &gt; &gt; CPU code. So we're losing SIMD with multiply so that's a 8x hit. GPUs have a
&gt; &gt; &gt; similar hit on speed while doing smaller multiplies which is another ~4x
&gt; &gt; &gt; slowdown.
&gt; &gt;
&gt; &gt; You lost me here. In what case are we "losing SIMD with multiply"? Do
&gt; &gt; you mean e.g. when we use specifically the 64x64-&gt;128 multiply on CPU?
&gt; &gt;
&gt; 
&gt; There is no 64x64-&gt;128 vector multiply on x86.
&gt; 
&gt; 
&gt; &gt; One of the reasons why I don't use 64x64-&gt;128 in yescrypt is that
&gt; &gt; 64x64-&gt;128 is not directly available on 32-bit CPUs and in 32-bit mode
&gt; &gt; on 64-bit CPUs. With 32-bit CPUs/mode in mind, it's 32x32-&gt;64 max, and
&gt; &gt; we do have SIMD with that.
&gt; &gt;
&gt; 
&gt; Most of what I was talking about is for arbitrarily large multiplies. I was
&gt; really thinking of Makwa. I probably should of mention this.
&gt; 
&gt; 
&gt; &gt; &gt; Last note, interleaving MULX (umul128), ADCX (_addcarryx_u64), and ADOX
&gt; &gt; &gt; (_addcarryx_u64) with VPMULUDQ (_mm256_mul_epu32) might get better
&gt; &gt; &gt; performance
&gt; &gt; &gt; on CPUs. MULX and VPMULUDQ should be similar in speed since VPMULUDQ can do
&gt; &gt; &gt; 4x(32bit*32bit=64bit) but there's 4x more work to do than doing
&gt; &gt; &gt; 64bit*64bit=128.
&gt; &gt; &gt; Interleaving them should mask some of the latency.
&gt; &gt;
&gt; &gt; I view potential SIMD/scalar interleaving as implementation detail, as
&gt; &gt; long as the hashing scheme provides sufficient/tunable parallelism.
&gt; &gt;
&gt; &gt; Why do you say that "4x(32bit*32bit=64bit)" is "4x more work" than
&gt; &gt; "64bit*64bit=128"?
&gt; 
&gt; Using "32bit*32bit=64bit" to do "64bit*64bit=128bit" takes four multiplies. Well
&gt; if you have a "33bit*33bit=66bit" or you only need "62bit*62bit=124bit", then
&gt; just three multiplies (and some extra additions and subtracts).
</pre>
<p><a href="https://www.openwall.com/blists/">Powered by blists</a> - <a href="https://lists.openwall.net">more mailing lists</a>


<p>




</body>
</html>

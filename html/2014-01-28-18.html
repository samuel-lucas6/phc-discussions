<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style type="text/css">
body { font-size: 16px; }
.cal_brief { text-align: center; }
.cal_brief td:first-child { background: inherit; }
.cal_brief td { background: #ccc; width: 5ex; padding: 2px; }
.cal_big { text-align: center; padding: 0; margin: 0; }
.cal_big td { padding: 0 2px; }
.cal_mon { text-align: center; }
.cal_mon th { font-size: small; padding: 0; margin: 0; }
.cal_mon td { background: #ccc; width: 5ex; height: 1.5em;
	padding: 2px; text-align: right; }
.cal_mon td[colspan] { background: inherit; }
.cal_mon sup { color: #F0F0F0; text-align: left; float: left;
	margin-top: -2pt; font-weight: bold; }
.cal_mon a { text-align: right; margin-left: -4em; float: right; }
</style>

<title>phc-discussions - Re: [PHC] my pre (if) submit proposal</title>


</head>

<BODY bgcolor="#E0E0E0" text="black" link="blue" alink="red" vlink="navy">



<TABLE bgcolor="white" width="100%" border="0" cellspacing="0" cellpadding="0">
<TR>
<TD width="39%">
<A HREF="http://lists.openwall.net">lists.openwall.net</A>
<TD width="1%" rowspan="3">&nbsp;
<TD width="60%" align="right" rowspan="3">
<A HREF="/">lists</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/announce/">announce</A>&nbsp;
<A HREF="http://www.openwall.com/lists/owl-users/">owl-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/owl-dev/">owl-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/john-users/">john-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/john-dev/">john-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/passwdqc-users/">passwdqc-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/yescrypt/">yescrypt</A>&nbsp;
<A HREF="http://www.openwall.com/lists/popa3d-users/">popa3d-users</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/oss-security/">oss-security</A>&nbsp;
<A HREF="http://www.openwall.com/lists/kernel-hardening/">kernel-hardening</A>&nbsp;
<A HREF="http://www.openwall.com/lists/musl/">musl</A>&nbsp;
<A HREF="http://www.openwall.com/lists/sabotage/">sabotage</A>&nbsp;
<A HREF="http://www.openwall.com/lists/tlsify/">tlsify</A>&nbsp;
<A HREF="http://www.openwall.com/lists/passwords/">passwords</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/crypt-dev/">crypt-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/xvendor/">xvendor</A>&nbsp;
/&nbsp;
<A HREF="/bugtraq/">Bugtraq</A>&nbsp;
<A HREF="/full-disclosure/">Full-Disclosure</A>&nbsp;
<A HREF="/linux-kernel/">linux-kernel</A>&nbsp;
linux-<A HREF="/netdev/">netdev</A>&nbsp;
<A HREF="/linux-ext4/">linux-ext4</A>&nbsp;
<a href="/linux-hardening/">linux-hardening</a>&nbsp;
<a href="/linux-cve-announce/">linux-cve-announce</a>&nbsp;
<a href="/phc-discussions/">PHC</a>&nbsp;
<TR><TD>
<DIV><FONT SIZE="-2"><I>Open Source and information security mailing list archives</I></FONT></DIV>
<TR><TD>&nbsp;
</TABLE>

<TABLE bgcolor="#B4D0DC" width="100%" border="0" cellspacing="0" cellpadding="1">
<TR><TD>
<TABLE width="100%" border="0" cellspacing="0" cellpadding="2">
<TR><TD bgcolor="#ECF8FF">

<a href="https://hashsuite.openwall.net/android">
Hash Suite for Android: free password hash cracker in your pocket</a>


</TABLE>
</TABLE>


<a href="17">[&lt;prev]</a> <a href="../../../2014/01/29/1">[next&gt;]</a> <a href="../../../2014/01/21/1">[&lt;thread-prev]</a> <a href=".">[day]</a> <a href="..">[month]</a> <a href="../..">[year]</a> <a href="../../..">[list]</a>
<pre style="white-space: pre-wrap">
Message-ID: &lt;715937984.107579.1390946276422.open-xchange&#64;email.1and1.com&gt;
Date: Tue, 28 Jan 2014 15:57:56 -0600 (CST)
From: Steve Thomas &lt;steve&#64;...tu.com&gt;
To: discussions&#64;...sword-hashing.net
Subject: Re: [PHC] my pre (if) submit proposal

Before I start I should fix the formulas. I messed up m vs m/r and had t**(1/2)
vs (m/r)**(1/2). Sorry about that I had a metal lapse after a brain fart.

For m = t*r/2

mem = (3/2*(r+c)+2*r)*(m/r)**(1/2)
time = 2.5x

i values             normal cost  extra cost
i=0...m/r/2-1        m/r/2        +0
i=m/r/2...m/r-1      m/r/2        +m/r/2
i=m/r...3m/r/2-1     m/r/2        +m/r
i=3m/r/2-1...2m/r-1  m/r/2        +3m/r/2


For m = t*r/4

mem = (7/2*(r+c)+2*r)*(m/r)**(1/2)
time = 4.5x

i values             normal cost  extra cost
i=0...m/r/2-1        m/r/2        +0
i=m/r/2...m/r-1      m/r/2        +m/r/2
i=m/r...3m/r/2-1     m/r/2        +m/r
i=3m/r/2-1...2m/r-1  m/r/2        +3m/r/2
i=2m/r...5m/r/2-1    m/r/2        +2m/r
i=5m/r/2...3m/r-1    m/r/2        +5m/r/2
i=3m/r...7m/r/2-1    m/r/2        +3m/r
i=7m/r/2-1...4m/r-1  m/r/2        +7m/r/2


In general

x = | 1   t/(m/r) ≤ 1.5
    | 2   otherwise
sizeOfMem = ((t/(m/r) - 1/2) * (r+c) + x * r) * (m/r)**(1/2)
timeFactor = t/(m/r) + 1/2

And because I can't keep track of c, m, r, t (I'm so c-m-r-t
&lt;<a href="https://www.youtube.com/watch?v=tcGQpjCztgA" rel="nofollow">https://www.youtube.com/watch?v=tcGQpjCztgA</a>&gt; [close enough :)]):
x = | 1   numberOfTimesMemoryIsRead ≤ 1.5
    | 2   otherwise
sizeOfMem = ((numberOfTimesMemoryIsRead - 1/2) * sizeOfState + x * sizeOfOutput)
* (blocksOfMemory)**(1/2)
timeFactor = numberOfTimesMemoryIsRead + 1/2


*** Note ***
This is for r divides m. Which you specify should not be the case in the paper,
but when r does not divide m this only adds a small amount of extra time-memory.


&gt; On January 20, 2014 at 6:35 PM Krisztián Pintér &lt;pinterkr&#64;...il.com&gt; wrote:
&gt;
&gt; Steve Thomas (at Monday, January 20, 2014, 11:14:16 AM):
&gt;
&gt; &gt; How I got this
&gt; &gt;
&gt; &gt; Always store every t**(1/2) states except the last m/2 since those
&gt; &gt; are never read.
&gt;
&gt; i might spend some more time on this later, but for now, i don't
&gt; understand some things. one is with this quote above. it seems that
&gt; the notion of state and "slot" in the mem array is mixed. the last m/2
&gt; memory locations will not be read. this is the last m/r/2 states, as a
&gt; state stores r words (which might be even 21 for keccak[c=256] and 64
&gt; bit).

Yeah I worded that poorly I should have said "Store every (m/r)**(1/2)th
state except states for the last m/r/2 since those are never read."

That's odd I knew this but just had a mental lapse. Pretty much replace
m with m/r. Oh also it's not "t**(1/2)" it's "(m/r)**(1/2)".


&gt; also note that this is true only for f=-1 and m = t*r/2. which is not
&gt; the case i intend to use in practice. for other cases, it is a little
&gt; bit more complicated.

I only looked at f=-1 because in your paper you state it as a perfect choice. I
only skimmed enough to find that. Also f=-1 should never be used regardless if
the sponge function is reverseable or not.


&gt; &gt; For 2nd m/2 regenerate blocks of t**(1/2) R's when needed. This adds m/2
&gt; &gt; extra work.
&gt;
&gt; i don't get what do you mean by "m/2 extra work". m/2 states can't be
&gt; recalculated in m/2 steps. you always need the previous state, and
&gt; then the previous to that, etc, since you need the C part. that leads
&gt; to, on average, (m/2)*t^0.5 / 2, if i'm not mistaken. anyway, so far
&gt; it does not seem to be a break, we still have O(^2) combined, ^1.5 (if
&gt; optimal parallelization is possible), which is expected in this early
&gt; phase.

* m/r/2 not m/2 (sorry)

You have to recalculate m/r/2 blocks of data.

m/r = 64
(m/r)**(1/2) = 8

* is a saved state it has all the info needed to get the next state
- is unknown data
+ recalculated data
0 mem is zero
&lt; reading pos
&gt; writting pos

Starting at:
                               &lt;&gt;
*-------*-------*-------*-------00000000000000000000000000000000

recalculate data (technically not needed this time since you just
calculated this data)
                               &lt;&gt;
*-------*-------*-------*+++++++00000000000000000000000000000000

                       &lt;                &gt;
*-------*-------*-------*+++++++*-------000000000000000000000000

recalculate data
                       &lt;                &gt;
*-------*-------*+++++++*-------*-------000000000000000000000000

               &lt;                                &gt;
*-------*-------*+++++++*-------*-------*-------0000000000000000

recalculate data
               &lt;                                &gt;
*-------*+++++++*-------*-------*-------*-------0000000000000000

       &lt;                                                &gt;
*-------*+++++++*-------*-------*-------*-------*-------00000000

recalculate data
       &lt;                                                &gt;
*+++++++*-------*-------*-------*-------*-------*-------00000000

      &lt;                                                  &gt;
*++++++-*-------*-------*-------*-------*-------*-------*0000000

     &lt;                                                    &gt;
*+++++--*-------*-------*-------*-------*-------*-------*+000000
...
&gt;                                                              &lt;
*-------*-------*-------*-------*-------*-------*-------*+++++++


&gt; &gt; For 3rd m/2 regenerate blocks of t**(1/2) R's when needed then regenerate
&gt; &gt; blocks of t**(1/2) R's from the other R's. This adds m extra work.
&gt;
&gt; this i don't follow at all. this phase seems to be exactly the same as
&gt; the previous. we read single written locations, are we not?

You keep the original states

! is a new saved state it has all the info needed to get the next state

Starting at:
&gt;                                                              &lt;
*-------*-------*-------*-------*-------*-------*-------*+++++++


        &gt;                                              &lt;
*-------*-------*-------*-------*-------*-------*-------*+++++++
!-------

recalculate data
        &gt;                                              &lt;
*-------*+++++++*-------*-------*-------*-------*-------*-------
!-------

more recalculate data
        &gt;                                              &lt;
*-------*+++++++*-------*-------*-------*-------*+++++++*-------
!-------

                &gt;                               &lt;
*-------*-------*-------*-------*-------*-------*+++++++*-------
!-------!-------

recalculate data
                &gt;                               &lt;
*-------*-------*+++++++*-------*-------*+++++++*-------*-------
!-------!-------

                        &gt;               &lt;
*-------*-------*-------*-------*-------*+++++++*-------*-------
!-------!-------!-------

...

                               &lt;&gt;
*-------*-------*-------*-------*-------*-------*-------*-------
!-------!-------!-------!+++++++

* Note you would keep the xored data in this part for the next part to save on
some caclutaltions.


&gt; &gt; You should note that you can do t**(1/3) and this increases the extra cost
&gt; &gt; by 2x
&gt; &gt; and memory by 2x for the constant in front of (r+c).
&gt;
&gt; and this is something i have no hope of understanding. how do you get
&gt; these numbers? bonus question: what is the difference between catena
&gt; and my access pattern that would cause this low exponent, while
&gt; catena-n approaches 2?

m/r = 64
(m/r)**(1/3) = 4

Starting at:
                               &lt;&gt;
*---------------*---------------*0000000000000000000000000000000

recalculate states (technically not needed this time since you just
calculated these states)
                               &lt;&gt;
*---------------*---*---*---*---*0000000000000000000000000000000

recalculate data (technically not needed this time since you just
calculated this data)
                               &lt;&gt;
*---------------*---*---*---*+++*0000000000000000000000000000000

                           &lt;        &gt;
*---------------*---*---*---*+++*---0000000000000000000000000000

recalculate data
                           &lt;        &gt;
*---------------*---*---*+++*---*---0000000000000000000000000000

                       &lt;                &gt;
*---------------*---*---*+++*---*-------000000000000000000000000

recalculate data
                       &lt;                &gt;
*---------------*---*+++*---*---*-------000000000000000000000000

                   &lt;                        &gt;
*---------------*---*+++*---*---*-----------00000000000000000000

recalculate data
                   &lt;                        &gt;
*---------------*+++*---*---*---*-----------00000000000000000000

recalculate states
               &lt;                                &gt;
*---*---*---*---*---------------*---------------0000000000000000

recalculate data
               &lt;                                &gt;
*---*---*---*+++*---------------*---------------0000000000000000
...

As you can see you are doing two passes over the missing data to regenerate
Also ln(64) ≈ 4.159 so after you hit 64^(1/4) it will cost more memory and time.
Since we are dealing with discrete amounts it might be sooner.

I plan on looking at memory cheating for Catena some time soon. I believe the
way the access pattern works you can store every (2**N)th state. For the first
pass after initialization, each step you take you'll need to do (2**N)/2 steps
on average to get the data you are looking for. On the second pass you need to
do (2**N)/2 steps which need to do (2**N)/2 steps each so ((2**N)/2)**2 steps.
Third pass it's ((2**N)/2)**3 steps and so on. Catena-3 is three passes and is
considered the minimum. I think they are/were debating between Catena-3 and
Catena-4. Hmm I see Bill has an argument for Catena-2.
<span style="font-family: times;"><strong>Content of type "</strong>text/html<strong>" skipped</strong></span>
</pre>
<p><a href="https://www.openwall.com/blists/">Powered by blists</a> - <a href="https://lists.openwall.net">more mailing lists</a>


<p>




</body>
</html>

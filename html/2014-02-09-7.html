<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style type="text/css">
body { font-size: 16px; }
.cal_brief { text-align: center; }
.cal_brief td:first-child { background: inherit; }
.cal_brief td { background: #ccc; width: 5ex; padding: 2px; }
.cal_big { text-align: center; padding: 0; margin: 0; }
.cal_big td { padding: 0 2px; }
.cal_mon { text-align: center; }
.cal_mon th { font-size: small; padding: 0; margin: 0; }
.cal_mon td { background: #ccc; width: 5ex; height: 1.5em;
	padding: 2px; text-align: right; }
.cal_mon td[colspan] { background: inherit; }
.cal_mon sup { color: #F0F0F0; text-align: left; float: left;
	margin-top: -2pt; font-weight: bold; }
.cal_mon a { text-align: right; margin-left: -4em; float: right; }
</style>

<title>phc-discussions - Re: [PHC] multiply-hardening (Re: NoelKDF ready for submission)</title>


</head>

<BODY bgcolor="#E0E0E0" text="black" link="blue" alink="red" vlink="navy">



<TABLE bgcolor="white" width="100%" border="0" cellspacing="0" cellpadding="0">
<TR>
<TD width="39%">
<A HREF="http://lists.openwall.net">lists.openwall.net</A>
<TD width="1%" rowspan="3">&nbsp;
<TD width="60%" align="right" rowspan="3">
<A HREF="/">lists</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/announce/">announce</A>&nbsp;
<A HREF="http://www.openwall.com/lists/owl-users/">owl-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/owl-dev/">owl-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/john-users/">john-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/john-dev/">john-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/passwdqc-users/">passwdqc-users</A>&nbsp;
<A HREF="http://www.openwall.com/lists/yescrypt/">yescrypt</A>&nbsp;
<A HREF="http://www.openwall.com/lists/popa3d-users/">popa3d-users</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/oss-security/">oss-security</A>&nbsp;
<A HREF="http://www.openwall.com/lists/kernel-hardening/">kernel-hardening</A>&nbsp;
<A HREF="http://www.openwall.com/lists/musl/">musl</A>&nbsp;
<A HREF="http://www.openwall.com/lists/sabotage/">sabotage</A>&nbsp;
<A HREF="http://www.openwall.com/lists/tlsify/">tlsify</A>&nbsp;
<A HREF="http://www.openwall.com/lists/passwords/">passwords</A>&nbsp;
/&nbsp;
<A HREF="http://www.openwall.com/lists/crypt-dev/">crypt-dev</A>&nbsp;
<A HREF="http://www.openwall.com/lists/xvendor/">xvendor</A>&nbsp;
/&nbsp;
<A HREF="/bugtraq/">Bugtraq</A>&nbsp;
<A HREF="/full-disclosure/">Full-Disclosure</A>&nbsp;
<A HREF="/linux-kernel/">linux-kernel</A>&nbsp;
linux-<A HREF="/netdev/">netdev</A>&nbsp;
<A HREF="/linux-ext4/">linux-ext4</A>&nbsp;
<a href="/linux-hardening/">linux-hardening</a>&nbsp;
<a href="/linux-cve-announce/">linux-cve-announce</a>&nbsp;
<a href="/phc-discussions/">PHC</a>&nbsp;
<TR><TD>
<DIV><FONT SIZE="-2"><I>Open Source and information security mailing list archives</I></FONT></DIV>
<TR><TD>&nbsp;
</TABLE>

<TABLE bgcolor="#B4D0DC" width="100%" border="0" cellspacing="0" cellpadding="1">
<TR><TD>
<TABLE width="100%" border="0" cellspacing="0" cellpadding="2">
<TR><TD bgcolor="#ECF8FF">

<a href="https://hashsuite.openwall.net/android">
Hash Suite for Android: free password hash cracker in your pocket</a>


</TABLE>
</TABLE>


<a href="6">[&lt;prev]</a> <a href="8">[next&gt;]</a> <a href="6">[&lt;thread-prev]</a> <a href="9">[thread-next&gt;]</a> <a href=".">[day]</a> <a href="..">[month]</a> <a href="../..">[year]</a> <a href="../../..">[list]</a>
<pre style="white-space: pre-wrap">
Message-ID: &lt;CAOLP8p7xCy68uQ7Tz5Oj=o5r1xFZBG4R6adizxqspHG8zBKyDQ&#64;mail.gmail.com&gt;
Date: Sun, 9 Feb 2014 08:01:43 -0500
From: Bill Cox &lt;waywardgeek&#64;...il.com&gt;
To: discussions&#64;...sword-hashing.net
Subject: Re: [PHC] multiply-hardening (Re: NoelKDF ready for submission)

On Sun, Feb 9, 2014 at 1:18 AM, Samuel Neves &lt;sneves&#64;....uc.pt&gt; wrote:
&gt; On 09-02-2014 04:26, Bill Cox wrote:
&gt;&gt; By the way, if you're familiar with results from skilled hand layout
&gt;&gt; of such circuits in advanced IC processes, I'd love to hear your
&gt;&gt; thoughts on Salsa20/8 latency with a custom hand-optimized layout in
&gt;&gt; the fastest processes.
&gt;
&gt; Sorry, can't help you there; my knowledge is limited to the software
&gt; side of things. That said, your estimate does look reasonable: [1]
&gt; reports 4 cycles (one cycle per double-round) for the highest-area
&gt; implementation, 8 cycles at roughly half the area, or 32 cycles at 1/4th
&gt; of the area. The most efficient (in throughput/gates) is the second choice.
&gt;
&gt; [1] <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=4746906" rel="nofollow">http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=4746906</a>

4 cycles per Salsa20/8 sounds about right to me.  In this paper, from
the abstract, they synthesized (not manually hand-crafted layout) to
180nm.  It probably ran &lt; 500MHz, if I had to guess (I have to ask for
access to papers through work, and password hashing requests annoy
them).  Scale it to 3.5-ish GHz, and it's probably a decent upper
bound for today's hand-crafted tech.  By the way, if you're doing a
28nm ASIC attack, I don't have any idea why anyone would be so lazy
that they synthesize the core rather than drawing every single polygon
by hand.  Once you've put out over $1M just for NRE for a full mask
set, why not go the extra mile an pay a layout guru $200K to build an
awesome hand-crafted core?  It's not like these transistors are all
different... it's the same full-adder + XOR replicated thousands of
times.

As for SIMD implementations, I'm afraid I'm a complete noob.  I really
shouldn't be trying to discuss SIMD with you guys... I'm way out of my
league here, but...

Wouldn't we want PMULLW rather than PMULUDQ?  4 packed 32x32-&gt;32 lower
mimics the C 32-bit multiply, and gives the same result for both
signed and unsigned multiplication, which is nice for Java
compatibility.  Either way, I see 5 cycle latency in Haswell here:

<a href="http://users.atw.hu/instlatx64/GenuineIntel00306C3_HaswellXeon_InstLatX86.txt" rel="nofollow">http://users.atw.hu/instlatx64/GenuineIntel00306C3_HaswellXeon_InstLatX86.txt</a>

I see 11 cycle latency for some instructions here:

<a href="http://users.atw.hu/instlatx64/GenuineIntel00406D8_Avoton_InstLatX64.txt" rel="nofollow">http://users.atw.hu/instlatx64/GenuineIntel00406D8_Avoton_InstLatX64.txt</a>

However, PMULLW is listed at 5 cycles latency even for this Atom CPU.
Just for comparison, it looks like my Ivy Bridge quad-core i7 does the
complete hash function in around 6 clocks on average just with gcc -O2
optimization.  I was guestimating 9 clocks for 4-way SIMD, so about
2.6X faster than a single thread doing it 4 times.  Is this about
right?  I get almost 2X speed increase for 2 threads, so the latency
per thread doesn't take much of a hit in that case.

As before, 2 threads almost double the throughput, with maybe 7-ish
clocks per hash per thread, and going to more threads helps a bit, but
not enough to justify the increase in latency per hash.

Going back to constant multiplication, my slow algorithm finished
overnight and got the same 7-add/sub answer.  Here's it's computation
of 1812433253:

2 = 1 &lt;&lt; 1
3 = 2 + 1
24 = 3 &lt;&lt; 3
27 = 24 + 3
55296 = 27 &lt;&lt; 11
16 = 2 &lt;&lt; 3
15 = 16 - 1
55311 = 55296 + 15
1812430848 = 55311 &lt;&lt; 15
19 = 16 + 3
2432 = 19 &lt;&lt; 7
2405 = 2432 - 27
1812433253 = 1812430848 + 2405

That was a fun little hack :-)

Bill
</pre>
<p><a href="https://www.openwall.com/blists/">Powered by blists</a> - <a href="https://lists.openwall.net">more mailing lists</a>


<p>




</body>
</html>
